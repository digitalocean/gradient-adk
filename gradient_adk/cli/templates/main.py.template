"""
Simple test agent using the gradient agent runtime with LangGraph.
"""

import os
from typing import Dict, TypedDict

from gradient import Gradient
from gradient_agents import entrypoint
from gradient_agents.langgraph import attach_graph
from langgraph.graph import StateGraph


class State(TypedDict):
    """The state of our graph."""

    input: str
    output: str


def llm_call(state: State) -> State:
    """Call the LLM"""

    inference_client = Gradient(
        model_access_key=os.environ.get(
            "GRADIENT_MODEL_ACCESS_KEY"
        )
    )

    # Call the model
    output = inference_client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": state["input"],
            }
        ],
        model="openai-gpt-oss-120b",
    )

    # Set the state
    state["output"] = output.choices[0].message.content
    
    return state


@entrypoint
def main(query: Dict, context: Dict):
    """Entrypoint"""

    # Setup the graph
    initial_state = State(
        input=query.get("prompt"),
        output=None
    )
    graph = StateGraph(State)
    graph.add_node("llm_call", llm_call)
    graph.set_entry_point("llm_call")
    
    # Attach the graph for instrumentation
    attach_graph(graph)
    app = graph.compile()
    
    # Invoke the app
    return app.invoke(initial_state)["output"]